{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b269e50b-edd4-47c7-b0bf-2d50957cddd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c1549",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35359b11-e771-4468-af80-c42229439e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\USER\\\\OneDrive\\\\Documents\\\\RoadToAustralia-Paper2\\\\Paper1-2-3-GC\\\\RawData012-Paper1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304e564-c068-4c82-97a2-400d8c8a8909",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50baa5-3b87-4d80-8b92-47cad2219567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check the shape of the data at this point\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e0902c-529b-491e-994d-88c9d380092e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#information on the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5f0ab-6613-4215-831e-8934cb9d5ef6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#statistics about the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de467d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().to_csv('dfDescribeGCR2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42295b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269af4f-346a-4c85-b151-f720ef1bb51e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check the presence of duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a11949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df. duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt to make data normally distributed, split data first in train-val-test\n",
    "\n",
    "X=df.drop(['GC'],axis=1) #X is \"remove the variable in '' \"\n",
    "y=df['GC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6289b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data spliting using 70:10 train test data ratio and randon seeding 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_model_train, X_test, y_model_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "#X_model_train,X_val,y_model_train,y_val=train_test_split(X_model_train,y_model_train,test_size=0.1111, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbe3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x train data {}'.format(X_model_train.shape))\n",
    "print('y train data {}'.format(y_model_train.shape))\n",
    "#print('x validate data  {}'.format(X_val.shape))\n",
    "#print('y validate data  {}'.format(y_val.shape))\n",
    "print('x test data  {}'.format(X_test.shape))\n",
    "print('y test data  {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV, cross_val_score #for grid search\n",
    "from bayes_opt import BayesianOptimization #for Bayesian Optimization\n",
    "from scipy.optimize import differential_evolution #for Genetic Algorithms and Differential Evolution\n",
    "from sklearn.metrics import accuracy_score\n",
    "#numpy for BOA, WOA, ABCA,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df5c35d-cc0b-48dc-a210-231e5eaa5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost = AdaBoostClassifier(random_state=42)\n",
    "GBDT = GradientBoostingClassifier(random_state=42)\n",
    "LightGBM = LGBMClassifier(random_state=42) \n",
    "RF = RandomForestClassifier(random_state=42)\n",
    "ET = ExtraTreesClassifier(n_estimators = 41, max_depth = 8, max_features = 13, random_state=42)\n",
    "# Train models\n",
    "\n",
    "models = {'AdaBoost': AdaBoost, 'GBDT': GBDT, 'LightGBM': LightGBM, 'RF': RF, 'ET': ET, 'RGF':RGF} \n",
    "#models = {'ET': ET} \n",
    "          \n",
    "          \n",
    "#'DT':DT, 'SVM':SVM, 'KNN':KNN, 'LR':LR, 'NB':NB, 'GPC':GPC, 'BPNN':BPNN, 'ELM':ELM}\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "model_et = ET\n",
    "#model_rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the models\n",
    "model_et.fit(X_model_train, y_model_train)\n",
    "#model_rf.fit(X_model_train, y_model_train)\n",
    "\n",
    "# Access feature importance\n",
    "feature_importance_et = model_et.feature_importances_\n",
    "#feature_importance_rf = model_rf.feature_importances_\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.45\n",
    "\n",
    "# Set the positions of bars on X-axis\n",
    "r1 = np.arange(len(feature_importance_et))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "fig=plt.gcf()\n",
    "# Plot feature importance\n",
    "plt.bar(r1, feature_importance_et, width=bar_width, label='Extra Trees')\n",
    "#plt.bar(r2, feature_importance_rf, width=bar_width, label='Random Forest', alpha=0.7)\n",
    "\n",
    "# Add annotations to each bar\n",
    "for i, score in enumerate(feature_importance_et):\n",
    "    plt.text(i, score , f'{score:.4f}', ha='center', va='bottom')\n",
    "\n",
    "#for i, score in enumerate(feature_importance_rf):\n",
    " #   plt.text(i + bar_width, score , f'{score:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('ExtraTreesFeatureImportance.tif', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240654f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "resultsTT = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_model_train, y_model_train)\n",
    "\n",
    "    # Make predictions on the training set\n",
    "    \n",
    "    \n",
    "    y_pred_train = model.predict(X_model_train)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_model_train, y_pred_train)\n",
    "    precision = precision_score(y_model_train, y_pred_train, average='weighted')  # Set 'average' parameter appropriately\n",
    "    recall = recall_score(y_model_train, y_pred_train, average='weighted')  # Set 'average' parameter appropriately\n",
    "    f1 = f1_score(y_model_train, y_pred_train, average='weighted')  # Set 'average' parameter appropriately\n",
    "    kappa = cohen_kappa_score(y_model_train, y_pred_train)  # Cohen's Kappa\n",
    "    confusion = confusion_matrix(y_model_train, y_pred_train)\n",
    "\n",
    "    resultsTT.append([name, accuracy, precision, recall, f1, kappa])\n",
    "\n",
    "    # Print the performance metrics\n",
    "    print(f\"{name} - Training Set Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Kappa: {kappa:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "        # Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3], yticklabels=[1, 2, 3])\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    #plt.title(f'Confusion Matrix for {name}')\n",
    "    #plt.savefig(f'{name}_ConfusionMatrixNew.tif', dpi=300, bbox_inches='tight')\n",
    "    #plt.show()\n",
    "# print the results\n",
    "headersTT = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa']\n",
    "print(pd.DataFrame(resultsTT, columns=headersTT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b315b-0f47-4aa1-a4d2-247aa3d8476b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "resultsTS = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_model_train, y_model_train)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision = precision_score(y_test, y_pred_test, average='weighted')  # Set 'average' parameter appropriately\n",
    "    recall = recall_score(y_test, y_pred_test, average='weighted')  # Set 'average' parameter appropriately\n",
    "    f1 = f1_score(y_test, y_pred_test, average='weighted')  # Set 'average' parameter appropriately\n",
    "    kappa = cohen_kappa_score(y_test, y_pred_test)  # Cohen's Kappa\n",
    "    confusion = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "    resultsTS.append([name, accuracy, precision, recall, f1, kappa, confusion])\n",
    "\n",
    "    # Print the performance metrics\n",
    "    print(f\"{name} - Testing Set Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Kappa: {kappa:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"\\n\")\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3], yticklabels=[1, 2, 3])\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    #plt.title(f'Confusion Matrix for {name}')\n",
    "    plt.savefig(f'{name}_ConfusionMatrixNew2.tif', dpi=300, bbox_inches='tight')\n",
    "    plt.show()    \n",
    "# print the results\n",
    "headersTS = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Confusion Matrix']\n",
    "print(pd.DataFrame(resultsTS, columns=headersTS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function to be optimized\n",
    "\n",
    "def optimize_ExtraTreesClassifier(n_estimators, max_depth, max_features):\n",
    "    # Create the egressor model with given hyperparameters\n",
    "    model = ExtraTreesClassifier(n_estimators=int(n_estimators), max_depth=int(max_depth), max_features=int(max_features))\n",
    "    # Calculate the cross-validation scores of the model\n",
    "    scores = cross_val_score(model, X_model_train, y_model_train, cv=10, scoring='accuracy')\n",
    "    # Return the average score across all cross-validation folds\n",
    "    accuracy = scores.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#start = time.time()\n",
    "# Define the search space for the hyperparameters\n",
    "pbounds = {'n_estimators': (1, 20), 'max_depth': (1, 8), 'max_features': (1, 8)}\n",
    "\n",
    "     \n",
    "# Create the Bayesian optimization object with the objective function and search space\n",
    "optimizer = BayesianOptimization(f=optimize_ExtraTreesClassifier, pbounds=pbounds, random_state=42)\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(init_points=10, n_iter=490)\n",
    "\n",
    "results = []\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    result = res['params'].copy()\n",
    "    result['target'] = res['target']\n",
    "    results.append(result)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_excel('GCoptimization_resultsET3.xlsx')\n",
    "\n",
    "                                                                              \n",
    "# Get the best hyperparameters\n",
    "best_n_estimators = optimizer.max['params']['n_estimators']\n",
    "#best_min_child_samples = optimizer.max['params']['min_child_samples']\n",
    "best_max_depth = optimizer.max['params']['max_depth']\n",
    "#best_min_samples_split = optimizer.max['params']['min_samples_split']\n",
    "#best_min_samples_leaf = optimizer.max['params']['min_samples_leaf']\n",
    "best_max_features = optimizer.max['params']['max_features']\n",
    "#best_learning_rate = optimizer.max['params']['learning_rate']\n",
    "#best_min_data_in_leaf = optimizer.max['params']['min_data_in_leaf']\n",
    "#est_boostrap = optimizer.max['params']['boostrap']\n",
    "#best_reg_alpha = optimizer.max['params']['reg_alpha']\n",
    "#best_colsample_bytree = optimizer.max['params']['colsample_bytree']\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "print(f\"Best max_depth: {best_max_depth}\")\n",
    "#print(f\"Best min_samples_split: {best_min_samples_split}\")\n",
    "\n",
    "#print(f\"Best min_child_samples: {best_min_child_samples}\")\n",
    "#print(f\"Best min_samples_leaf: {best_min_samples_leaf}\")\n",
    "print(f\"Best max_features: {best_max_features}\")\n",
    "#print(f\"Best learning_rate: {best_learning_rate}\")\n",
    "#print(f\"Best min_data_in_leaf: {best_min_data_in_leaf}\")\n",
    "#rint(f\"Best boostrap: {best_boostrap}\")\n",
    "#print(f\"Best reg_alpha: {best_reg_alpha}\")\n",
    "#print(f\"Best colsample_bytree: {best_colsample_bytree}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the best hyperparameters to train the final model\n",
    "model = ExtraTreesClassifier(n_estimators=int(best_n_estimators), max_depth=int(best_max_depth), max_features=int(best_max_features), random_state=42)\n",
    "model.fit(X_model_train, y_model_train)\n",
    "y_pred_train = model.predict(X_model_train)\n",
    "y_pred_test=model.predict(X_test)\n",
    "Trainingset_accuracy = accuracy_score(y_model_train, y_pred_train)\n",
    "Testset_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Accuracy on Training Set for the new model is\", Trainingset_accuracy)\n",
    "print(\"Accuracy on Test Set for the new model is\", Testset_accuracy)\n",
    "#print(\"This process consumed %s minutes:\" % ((time.time() - start)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd2c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
